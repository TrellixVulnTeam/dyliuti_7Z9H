**“纸上得来终觉浅，绝知此事要躬行。”  —— 陆游**

**"Practice，practice，practice and summary makes perfect" —— dyliuti**

------



**马尔可夫：**

1.马尔可夫链的状态序列的概率求的是联合概率分布，具体到语言模型，该联合概率就对应句子的可能性。

2.通过简化状态依赖关系（随机变量非独立），形成一阶/二阶马尔可夫链。

3.用隐马尔可夫概念来套，就是状态可见，观察序列等同于状态序列，两者之间是等价关系，不是随机过程。

4.马尔可夫的计算简单，计数得评率，再求极大似然

**隐马尔可夫：**

问题1：给定状态转移矩阵和概率分布矩阵的情况下，观察序列的概率（解码问题）。

问题2：给定观察序列、状态转移矩阵和概率分布矩阵的情况下，求最优状态序列，最好解释观测序列（哪个状态序列->已有的观测序列的概率最大）。需要路径记忆。

问题3：给定观测序列的情况下，如何根据最大似然估计求状态转移矩阵和概率分布矩阵，使观测序列在两者的前提下概率最大。

<br>

**小总结：**

隐马尔可夫问题的常规解法是用动态规划，简化的状态依赖假设就说明了其是动态规划中的一种。通过状态转移矩阵，可推断出初始状态。问题1、2、3都可分析状态转移矩阵得到解的步骤。

有意思的是观察问题3，给定观测序列，相当于是给定了label。使观测序列在两者的前提下概率最大，即可调节状态转移矩阵和概率分布矩阵（相当于神经网络中前向传递的权重）。可以将状态转移公式，转换为矩阵形式点积与相乘的形式。目标是求最大概率P，定义损失函数-log(P)，转换为损失函数最小化问题，即可用梯度下降的数值方法求得最优状态与状态转移矩阵。

<br>

**文件说明：**

1st_sites.py与2st_frost.py是马尔可夫模型的应用。



<br>

**数据集下载：**

[Markov数据集下载，解压后将Markov文件夹放在Data文件夹下](https://drive.google.com/file/d/1G3rmYtY7Io754vVogcEdtskvTqYfsiuF/view?usp=sharing)

